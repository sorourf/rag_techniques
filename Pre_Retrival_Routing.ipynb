{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sorou\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pprint\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        ..., \n",
    "        description=\"Given a user question choose which datasource would be most relevant for answering their question\",\n",
    "    )\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt \n",
    "template = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\n",
    "\n",
    "User Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "\n",
    "# Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Define router \n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RouteQuery(datasource='python_docs')\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"]) \"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke(question)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_route(result):\n",
    "    if \"python_docs\" in result.datasource.lower():\n",
    "        ### Logic here \n",
    "        return \"chain for python_docs\"\n",
    "    elif \"js_docs\" in result.datasource.lower():\n",
    "        ### Logic here \n",
    "        return \"chain for js_docs\"\n",
    "    else:\n",
    "        ### Logic here \n",
    "        return \"golang_docs\"\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for python_docs'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "A black hole is a region in space where gravity is so strong that nothing, not even light, can escape from it. It is formed when a massive star collapses in on itself at the end of its life cycle. The gravity in a black hole is so intense that it creates a singularity, a point of infinite density at the center. Black holes have a profound impact on the surrounding space and time, distorting everything around them.\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Two prompts\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "# Embed prompts\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Route question to prompt \n",
    "def prompt_router(input):\n",
    "    # Embed question\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # Chosen prompt \n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"What's a black hole\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enhanced Version of Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**User Query 1:** How does gravity affect time?\n",
      "Using PHYSICS Prompt\n",
      "**Response:** Gravity affects time by causing time dilation. According to Einstein's theory of relativity, gravity warps spacetime, causing time to move slower in stronger gravitational fields. This means that time actually passes at a different rate depending on how close you are to a massive object like a planet or star. This phenomenon has been confirmed through experiments with atomic clocks in high and low gravity environments, such as on Earth's surface compared to on the International Space Station.\n",
      "\n",
      "\n",
      "**User Query 2:** What is the quadratic formula?\n",
      "Using MATH Prompt\n",
      "**Response:** The quadratic formula is as follows:\n",
      "\n",
      "For a quadratic equation in the form ax^2 + bx + c = 0, the solutions can be found using the formula:\n",
      "\n",
      "x = (-b ± √(b^2 - 4ac)) / 2a\n",
      "\n",
      "\n",
      "**User Query 3:** Explain the pH scale in chemistry.\n",
      "Using CHEMISTRY Prompt\n",
      "**Response:** Chemical reactions are processes in which substances, called reactants, interact to form new substances, called products. During a chemical reaction, bonds between atoms are broken and new bonds are formed, resulting in a rearrangement of atoms to create different compounds.\n",
      "\n",
      "At the atomic level, each element is made up of a nucleus containing protons and neutrons, surrounded by electrons in orbitals. The number of protons in the nucleus determines the element's atomic number, while the sum of protons and neutrons determines the atomic mass. Atoms can form molecules by sharing electrons in covalent bonds or transferring electrons in ionic bonds.\n",
      "\n",
      "The pH scale is a measure of the acidity or basicity of a solution, ranging from 0 to 14. A pH of 7 is considered neutral, meaning the solution is neither acidic nor basic. Solutions with a pH below 7 are acidic, with lower numbers indicating stronger acidity. Solutions with a pH above 7 are basic, with higher numbers indicating stronger basicity.\n",
      "\n",
      "The pH scale is logarithmic, meaning a one-unit change in pH represents a tenfold change in the concentration of hydrogen ions in the solution. Acids release hydrogen ions (H+) when dissolved in water, while bases release hydroxide ions (OH-). The pH of a solution can be measured using indicators, pH meters, or calculations based on the concentrations of H+ and OH- ions.\n",
      "\n",
      "Understanding the pH scale is important in various industries, such as agriculture, medicine, and environmental science, as it can affect the behavior of chemicals and biological systems. By monitoring and adjusting pH levels, we can control the outcome of chemical reactions and maintain optimal conditions for desired processes.\n",
      "\n",
      "\n",
      "**User Query 4:** How does DNA replication work?\n",
      "Using BIOLOGY Prompt\n",
      "**Response:** DNA replication is the process by which a cell makes an identical copy of its DNA molecule. This is crucial for cell division and for passing on genetic information to offspring.\n",
      "\n",
      "The process of DNA replication begins with the unwinding of the DNA double helix structure. Enzymes called helicases separate the two strands of the DNA, creating a replication fork. \n",
      "\n",
      "Next, another enzyme called DNA polymerase adds new nucleotides to each of the separated strands, following the base pairing rules (A pairs with T, and C pairs with G). This results in two identical strands of DNA being created, one for each of the original parent strands.\n",
      "\n",
      "After the new strands have been formed, other enzymes help to proofread and correct any errors in the newly synthesized DNA. This ensures that the new DNA molecules are accurate copies of the original DNA.\n",
      "\n",
      "In summary, DNA replication is a highly regulated and precise process that ensures genetic information is faithfully passed on from one generation to the next.\n",
      "\n",
      "\n",
      "**User Query 5:** How do I reverse a linked list in Python?\n",
      "Using MATH Prompt\n",
      "**Response:** To reverse a linked list in Python, you can follow these steps:\n",
      "\n",
      "1. Define a Node class to represent each node in the linked list. Each node should have a value and a reference to the next node in the list.\n",
      "2. Create a LinkedList class to manage the operations on the linked list, including adding nodes and reversing the list.\n",
      "3. Iterate through the original linked list and store the nodes in a list.\n",
      "4. Create a new linked list and add the nodes from the list in reverse order.\n",
      "5. Return the new reversed linked list.\n",
      "\n",
      "Would you like me to solve the entire problem step by step for you?\n",
      "\n",
      "\n",
      "**User Query 6:** What happens to an electron in a magnetic field?\n",
      "Using CHEMISTRY Prompt\n",
      "**Response:** When an electron is placed in a magnetic field, it experiences a force known as the Lorentz force which causes it to move in a circular or helical path depending on the strength and direction of the magnetic field. This is because the electron is charged and when it moves through a magnetic field, it interacts with the magnetic field causing it to curve its path.\n",
      "\n",
      "The direction of the force on the electron is perpendicular to both the velocity of the electron and the direction of the magnetic field. This results in the electron moving in a circular path around the magnetic field lines. The radius of the circular path is determined by the velocity of the electron, the strength of the magnetic field, and the mass of the electron.\n",
      "\n",
      "This phenomenon is the basis for technologies such as magnetic resonance imaging (MRI) which utilizes the behavior of electrons in magnetic fields to create detailed images of the inside of the human body.\n",
      "\n",
      "In summary, when an electron is placed in a magnetic field, it experiences a force causing it to move in a circular or helical path determined by the strength and direction of the magnetic field.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#  Define multiple subject-specific prompts\n",
    "prompts = {\n",
    "    \"physics\": \"\"\"You are a very smart physics professor. \\\n",
    "    You excel at explaining physics concepts in a concise and easy-to-understand manner. \\\n",
    "    If you don't know the answer, just admit it.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\"\"\",\n",
    "\n",
    "    \"math\": \"\"\"You are a skilled mathematician. \\\n",
    "    You excel at breaking down complex problems into simpler steps. \\\n",
    "    Answer each component separately before solving the entire problem.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\"\"\",\n",
    "\n",
    "    \"chemistry\": \"\"\"You are a chemistry expert. \\\n",
    "    Explain chemical reactions, atomic structures, and related topics clearly.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\"\"\",\n",
    "\n",
    "    \"biology\": \"\"\"You are a knowledgeable biologist. \\\n",
    "    Explain biological concepts such as cell functions, DNA, and evolution in simple terms.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\"\"\",\n",
    "\n",
    "    \"computer_science\": \"\"\"You are a software engineer. \\\n",
    "    Answer programming-related questions, explain algorithms, and debugging techniques.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\"\"\"\n",
    "}\n",
    "\n",
    "#  Generate embeddings for each prompt\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_names = list(prompts.keys())  # [\"physics\", \"math\", \"chemistry\", \"biology\", \"computer_science\"]\n",
    "prompt_texts = list(prompts.values())  # The actual templates\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_texts)  # Precomputed embeddings for routing\n",
    "\n",
    "#  Function to find the best prompt based on semantic similarity\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])  # Embed the input question\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]  # Compute cosine similarity\n",
    "    best_match_idx = similarity.argmax()  # Get the index of the most similar prompt\n",
    "\n",
    "    # Multi-prompt blending: If multiple subjects are relevant, mix them!\n",
    "    sorted_indices = similarity.argsort()[::-1]  # Sort similarity scores in descending order\n",
    "    top_similarities = similarity[sorted_indices[:2]]  # Take top 2 matching prompts\n",
    "    threshold = 0.8  # Set a threshold for similarity blending\n",
    "\n",
    "    if len(top_similarities) > 1 and top_similarities[1] > threshold:\n",
    "        chosen_prompts = [prompt_names[idx] for idx in sorted_indices[:2]]\n",
    "        print(f\"Blending: {chosen_prompts}\")\n",
    "        blended_template = f\"{prompts[chosen_prompts[0]]}\\n{prompts[chosen_prompts[1]]}\"\n",
    "        return PromptTemplate.from_template(blended_template)\n",
    "    \n",
    "    # Otherwise, return the best single match\n",
    "    best_prompt_name = prompt_names[best_match_idx]\n",
    "    print(f\"Using {best_prompt_name.upper()} Prompt\")\n",
    "    return PromptTemplate.from_template(prompts[best_prompt_name])\n",
    "\n",
    "#  Define the full LangChain pipeline\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}  # Pass user query\n",
    "    | RunnableLambda(prompt_router)  # Choose or blend prompts based on similarity\n",
    "    | ChatOpenAI()  # Query the LLM with the chosen prompt\n",
    "    | StrOutputParser()  # Convert the response into a clean string\n",
    ")\n",
    "\n",
    "#  Example Usage\n",
    "test_questions = [\n",
    "    \"How does gravity affect time?\",\n",
    "    \"What is the quadratic formula?\",\n",
    "    \"Explain the pH scale in chemistry.\",\n",
    "    \"How does DNA replication work?\",\n",
    "    \"How do I reverse a linked list in Python?\",\n",
    "    \"What happens to an electron in a magnetic field?\"\n",
    "]\n",
    "\n",
    "# Run multiple test cases\n",
    "for i, question in enumerate(test_questions):\n",
    "    print(f\"\\n**User Query {i+1}:** {question}\")\n",
    "    response = chain.invoke( question)\n",
    "    print(f\"**Response:** {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
